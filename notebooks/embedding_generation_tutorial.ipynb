{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b99a266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint keys: ['model_state_dict', 'loss_state_dict', 'optimizer_state_dict']\n",
      "Total model parameters: 1170\n",
      "Texture Embedding Layer:\n",
      "   Shape: torch.Size([256, 1536])\n",
      "   Embedding dimensions: 256\n",
      "   Input features: 1536\n",
      "   Has minutia branch: True\n",
      "   Minutia embedding dimensions: 256\n",
      "Loss function info:\n",
      "   minu_loss_fun.center_loss_fun.centers: torch.Size([8000, 256])\n",
      "   texture_loss_fun.center_loss_fun.centers: torch.Size([8000, 256])\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "ORIGINAL_MODEL_PATH = os.path.abspath(\"trained_models/best_model.pyt\")\n",
    "\n",
    "# Load checkpoints\n",
    "checkpoint = torch.load(ORIGINAL_MODEL_PATH, map_location='cpu')\n",
    "\n",
    "print(f\"Checkpoint keys: {list(checkpoint.keys())}\")\n",
    "print(f\"Total model parameters: {len(checkpoint['model_state_dict'].keys())}\")\n",
    "\n",
    "tex_weight = checkpoint['model_state_dict']['texture_branch._6_linear.weight']\n",
    "print(\"Texture Embedding Layer:\")\n",
    "print(f\"   Shape: {tex_weight.shape}\")\n",
    "print(f\"   Embedding dimensions: {tex_weight.shape[0]}\")\n",
    "print(f\"   Input features: {tex_weight.shape[1]}\")\n",
    "\n",
    "# Check if there's a minutia branch\n",
    "has_minutia = 'minutia_embedding._4_linear.weight' in checkpoint['model_state_dict']\n",
    "print(f\"   Has minutia branch: {'True' if has_minutia else 'False'}\")\n",
    "\n",
    "if has_minutia:\n",
    "    min_weight = checkpoint['model_state_dict']['minutia_embedding._4_linear.weight']\n",
    "    print(f\"   Minutia embedding dimensions: {min_weight.shape[0]}\")\n",
    "\n",
    "# Try to determine number of training subjects from loss layer\n",
    "loss_keys = [k for k in checkpoint['loss_state_dict'].keys() if 'classification' in k or 'centers' in k]\n",
    "print(\"Loss function info:\")\n",
    "for key in loss_keys[:5]:  # Show first 5\n",
    "    print(f\"   {key}: {checkpoint['loss_state_dict'][key].shape}\")\n",
    "\n",
    "# Check for center loss centers which would tell us num_subjects\n",
    "if 'texture_center_loss.centers' in checkpoint['loss_state_dict']:\n",
    "    centers = checkpoint['loss_state_dict']['texture_center_loss.centers']\n",
    "    num_training_subjects = centers.shape[0]\n",
    "    print(f\"Detected training subjects: {num_training_subjects}\")\n",
    "    print(f\"   (from center loss centers shape: {centers.shape})\")\n",
    "    \n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "96f804d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best model from /Users/koechian/Documents/Projects/fixed-length-fingerprint-extractors/notebooks/trained_models/best_model.pyt\n"
     ]
    }
   ],
   "source": [
    "from flx.extractor.fixed_length_extractor import (\n",
    "    get_DeepPrint_TexMinu, \n",
    "    DeepPrintExtractor\n",
    ")\n",
    "\n",
    "extractor: DeepPrintExtractor = get_DeepPrint_TexMinu(num_training_subjects=8000, num_dims=256)\n",
    "\n",
    "MODEL_DIR: str = os.path.abspath(\"trained_models/\")\n",
    "extractor.load_best_model(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "08f46315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created IdentifierSet with 8 subjects and a total of 16 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:05<00:00,  5.24s/it]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.24s/it]\n"
     ]
    }
   ],
   "source": [
    "if 'extractor' in globals() and extractor is not None:\n",
    "\n",
    "    from flx.data.dataset import *\n",
    "    from flx.data.image_loader import FVC2004Loader\n",
    "    from flx.data.transformed_image_loader import TransformedImageLoader\n",
    "    from flx.image_processing.binarization import LazilyAllocatedBinarizer\n",
    "    from flx.data.image_helpers import pad_and_resize_to_deepprint_input_size\n",
    "    \n",
    "    DATASET_PATH = os.path.abspath(\"dataset/split\")\n",
    "    \n",
    "    image_loader = TransformedImageLoader(\n",
    "        images=FVC2004Loader(DATASET_PATH),\n",
    "        poses=None, \n",
    "        transforms=[\n",
    "            LazilyAllocatedBinarizer(5.0),\n",
    "            pad_and_resize_to_deepprint_input_size,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    dataset = Dataset(image_loader, image_loader.ids)\n",
    "\n",
    "    texture_embeddings, minutae_embeddings = extractor.extract(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7b60c",
   "metadata": {},
   "source": [
    "101 - My Index\n",
    "102 - My Thumb\n",
    "103_1 - Nelson's Thumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3995f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texture embedding shape: (256,)\n",
      "Created IdentifierSet with 8 subjects and a total of 16 samples.\n",
      "Created IdentifierSet with 8 subjects and a total of 16 samples.\n",
      "Created IdentifierSet with 8 subjects and a total of 16 samples.\n",
      "Combined embedding shape: (512,)\n",
      "\n",
      "================================================================================\n",
      "Available Identifiers and Images (16 total):\n",
      "================================================================================\n",
      "[ 0] ID(subject=100, impression=0) -> 101_1.tif\n",
      "[ 1] ID(subject=100, impression=1) -> 101_2.tif\n",
      "[ 2] ID(subject=101, impression=0) -> 102_1.tif\n",
      "[ 3] ID(subject=101, impression=1) -> 102_2.tif\n",
      "[ 4] ID(subject=102, impression=0) -> 103_1.tif\n",
      "[ 5] ID(subject=102, impression=1) -> 103_2.tif\n",
      "[ 6] ID(subject=103, impression=0) -> 104_1.tif\n",
      "[ 7] ID(subject=103, impression=1) -> 104_2.tif\n",
      "[ 8] ID(subject=104, impression=0) -> 105_1.tif\n",
      "[ 9] ID(subject=104, impression=1) -> 105_2.tif\n",
      "[10] ID(subject=105, impression=0) -> 106_1.tif\n",
      "[11] ID(subject=105, impression=1) -> 106_2.tif\n",
      "[12] ID(subject=106, impression=0) -> 107_1.tif\n",
      "[13] ID(subject=106, impression=1) -> 107_2.tif\n",
      "[14] ID(subject=107, impression=0) -> 108_1.tif\n",
      "[15] ID(subject=107, impression=1) -> 108_2.tif\n",
      "\n",
      "================================================================================\n",
      "Similarity Test (using combined texture + minutiae embeddings):\n",
      "================================================================================\n",
      "\n",
      "Comparing:\n",
      "  [2] 102_1.tif\n",
      "  [3] 102_2.tif\n",
      "  Similarity: 1.733871\n",
      "\n",
      "Comparing:\n",
      "  [2] 102_1.tif\n",
      "  [4] 103_1.tif\n",
      "  Similarity: 1.227647\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from flx.data.embedding_loader import EmbeddingLoader\n",
    "\n",
    "# Show sample embedding shape    \n",
    "sample_id = list(dataset.ids)[0]\n",
    "sample_embeddings = texture_embeddings.get(sample_id)\n",
    "print(f\"Texture embedding shape: {sample_embeddings.shape}\")\n",
    "\n",
    "# Combine embeddings for full DeepPrint representation\n",
    "combined_embeddings = EmbeddingLoader.combine(texture_embeddings, minutae_embeddings)\n",
    "print(f\"Combined embedding shape: {combined_embeddings.get(sample_id).shape}\")\n",
    "\n",
    "# Show all available identifiers with their image files\n",
    "ids_list = list(dataset.ids)\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Available Identifiers and Images ({len(ids_list)} total):\")\n",
    "print(f\"{'='*80}\")\n",
    "for idx, id in enumerate(ids_list[:20]):\n",
    "    filepath = image_loader._images._files.get(id)\n",
    "    filename = filepath.split('/')[-1]\n",
    "    print(f\"[{idx:2d}] ID(subject={id.subject}, impression={id.impression}) -> {filename}\")\n",
    "\n",
    "# Sanity check: Test on a pair using FULL DeepPrint representation (texture + minutiae)\n",
    "if len(ids_list) >= 10:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"Similarity Test (using combined texture + minutiae embeddings):\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Choose which identifiers to compare (modify these indices)\n",
    "    idx1, idx2, idx3 = 0, 1, 4\n",
    "    id1, id2, id3 = ids_list[idx1], ids_list[idx2], ids_list[idx3]\n",
    "    \n",
    "    # Get combined embeddings\n",
    "    emb1 = combined_embeddings.get(id1)\n",
    "    emb2 = combined_embeddings.get(id2)\n",
    "    emb3 = combined_embeddings.get(id3)\n",
    "    \n",
    "    # Compute similarities (dot product of concatenated embeddings)\n",
    "    same_score = np.dot(emb1, emb2)\n",
    "    diff_score = np.dot(emb1, emb3)\n",
    "    \n",
    "    print(f\"\\nComparing:\")\n",
    "    print(f\"  [{idx1}] {image_loader._images._files.get(id1).split('/')[-1]}\")\n",
    "    print(f\"  [{idx2}] {image_loader._images._files.get(id2).split('/')[-1]}\")\n",
    "    print(f\"  Similarity: {same_score:.6f}\")\n",
    "    \n",
    "    print(f\"\\nComparing:\")\n",
    "    print(f\"  [{idx1}] {image_loader._images._files.get(id1).split('/')[-1]}\")\n",
    "    print(f\"  [{idx3}] {image_loader._images._files.get(id3).split('/')[-1]}\")\n",
    "    print(f\"  Similarity: {diff_score:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f26ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 10 subjects\n",
      "Unique subjects: [100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n",
      "Unique impressions: [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "\n",
      "Creating benchmark with:\n",
      "  Subjects: [100, 101, 102, 103, 104, 105, 106, 107, 108, 109]\n",
      "  Impressions per subject: [0, 1, 2, 3, 4, 5, 6, 7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 20919.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 54971.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 48998.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 20919.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 54971.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 48998.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 56833.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 22028.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 23096.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 62508.26it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 29937.93it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 22028.91it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 23096.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 62508.26it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 29937.93it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created IdentifierSet with 10 subjects and a total of 80 samples.\n",
      "Created IdentifierSet with 10 subjects and a total of 80 samples.\n",
      "Created IdentifierSet with 10 subjects and a total of 80 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 920/920 [00:00<00:00, 113369.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Equal-Error-Rate: 0.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from flx.scripts.generate_benchmarks import create_verification_benchmark\n",
    "from flx.benchmarks.matchers import CosineSimilarityMatcher\n",
    "from flx.data.embedding_loader import EmbeddingLoader\n",
    "\n",
    "ids_list = list(dataset.ids)\n",
    "unique_subjects = sorted(set(id.subject for id in ids_list))\n",
    "unique_impressions = sorted(set(id.impression for id in ids_list))\n",
    "\n",
    "print(f\"Dataset has {dataset.num_subjects} subjects\")\n",
    "print(f\"Unique subjects: {unique_subjects}\")\n",
    "print(f\"Unique impressions: {unique_impressions}\")\n",
    "\n",
    "NUM_IMPRESSIONS_PER_SUBJECT = min(8, len(unique_impressions))\n",
    "impressions_to_use = unique_impressions[:NUM_IMPRESSIONS_PER_SUBJECT]\n",
    "\n",
    "print(f\"  Subjects: {unique_subjects}\")\n",
    "print(f\"  Impressions per subject: {impressions_to_use}\")\n",
    "\n",
    "benchmark = create_verification_benchmark(\n",
    "    subjects=unique_subjects,\n",
    "    impressions_per_subject=impressions_to_use)\n",
    "\n",
    "embeddings = EmbeddingLoader.combine(texture_embeddings, minutae_embeddings)\n",
    "matcher = CosineSimilarityMatcher(embeddings)\n",
    "\n",
    "results = benchmark.run(matcher)\n",
    "\n",
    "print(f\"\\nEqual-Error-Rate: {results.get_equal_error_rate()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13bbaf14",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VerificationResult' object has no attribute '_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m genuine_scores = []\n\u001b[32m      6\u001b[39m impostor_scores = []\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m comparison \u001b[38;5;129;01min\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_results\u001b[49m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m comparison.comparison.sample1.subject == comparison.comparison.sample2.subject:\n\u001b[32m     10\u001b[39m         genuine_scores.append(comparison.similarity)\n",
      "\u001b[31mAttributeError\u001b[39m: 'VerificationResult' object has no attribute '_results'"
     ]
    }
   ],
   "source": [
    "# Diagnostic: Check similarity score distributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get all genuine (same subject) and impostor (different subject) scores\n",
    "genuine_scores = []\n",
    "impostor_scores = []\n",
    "\n",
    "for comparison in results._results:\n",
    "    if comparison.comparison.sample1.subject == comparison.comparison.sample2.subject:\n",
    "        genuine_scores.append(comparison.similarity)\n",
    "    else:\n",
    "        impostor_scores.append(comparison.similarity)\n",
    "\n",
    "genuine_scores = np.array(genuine_scores)\n",
    "impostor_scores = np.array(impostor_scores)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Score Distribution Analysis:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Genuine comparisons: {len(genuine_scores)}\")\n",
    "print(f\"  Mean: {genuine_scores.mean():.4f}\")\n",
    "print(f\"  Std:  {genuine_scores.std():.4f}\")\n",
    "print(f\"  Min:  {genuine_scores.min():.4f}\")\n",
    "print(f\"  Max:  {genuine_scores.max():.4f}\")\n",
    "\n",
    "print(f\"\\nImpostor comparisons: {len(impostor_scores)}\")\n",
    "print(f\"  Mean: {impostor_scores.mean():.4f}\")\n",
    "print(f\"  Std:  {impostor_scores.std():.4f}\")\n",
    "print(f\"  Min:  {impostor_scores.min():.4f}\")\n",
    "print(f\"  Max:  {impostor_scores.max():.4f}\")\n",
    "\n",
    "print(f\"\\nSeparation (genuine mean - impostor mean): {genuine_scores.mean() - impostor_scores.mean():.4f}\")\n",
    "print(f\"Equal-Error-Rate: {results.get_equal_error_rate():.4f}\")\n",
    "\n",
    "# Plot distributions\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(genuine_scores, bins=30, alpha=0.7, label='Genuine', color='green', edgecolor='black')\n",
    "plt.hist(impostor_scores, bins=30, alpha=0.7, label='Impostor', color='red', edgecolor='black')\n",
    "plt.xlabel('Similarity Score')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Score Distributions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(genuine_scores, bins=30, alpha=0.7, label='Genuine', color='green', density=True, edgecolor='black')\n",
    "plt.hist(impostor_scores, bins=30, alpha=0.7, label='Impostor', color='red', density=True, edgecolor='black')\n",
    "plt.xlabel('Similarity Score')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Normalized Distributions')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  - Good separation: genuine scores should be much higher than impostor scores\")\n",
    "print(\"  - Overlap indicates discrimination difficulty\")\n",
    "print(\"  - For good performance: genuine mean should be > 0.8, impostor mean < 0.4\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
